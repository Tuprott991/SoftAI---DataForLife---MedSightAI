import torch
import torch.nn.functional as F
import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

# Import CSRModel thay vÃ¬ model cÅ©
from src.model import CSRModel

# --- Cáº¤U HÃŒNH ---
CLASS_NAMES = [
    'Aortic enlargement',
    'Atelectasis',
    'Calcification',
    'Cardiomegaly',
    'Consolidation',
    'ILD',
    'Infiltration',
    'Lung Opacity',
    'Nodule/Mass',
    'Other lesion',
    'Pleural effusion',
    'Pleural thickening',
    'Pneumothorax',
    'Pulmonary fibrosis'
]

# --- THIáº¾T Láº¬P BIáº¾N ---
# ÄÆ°á»ng dáº«n Ä‘áº¿n áº£nh vÃ  checkpoint
image_path = "/kaggle/input/vindr-image-convert/train_png_384/9a5094b2563a1ef3ff50dc5c7ff71345.png"  # Thay báº±ng Ä‘Æ°á»ng dáº«n áº£nh cá»§a báº¡n
checkpoint_path = "/kaggle/input/vin-csr-training/checkpoints/csr_final_model.pth"  # Thay báº±ng Ä‘Æ°á»ng dáº«n checkpoint cá»§a báº¡n

# Cáº¥u hÃ¬nh mÃ´ hÃ¬nh
num_classes = 14
num_prototypes = 10
model_name = "resnet50"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ÄÆ°á»ng dáº«n lÆ°u káº¿t quáº£
save_path = "./results/output.png"  # Thay báº±ng Ä‘Æ°á»ng dáº«n báº¡n muá»‘n lÆ°u áº£nh káº¿t quáº£

# --- HÃ€M TIá»€N Xá»¬ LÃ ---
def preprocess_image(image_path, target_size=384):
    """Äá»c vÃ  tiá»n xá»­ lÃ½ áº£nh"""
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"File not found: {image_path}")
        
    # Äá»c áº£nh grayscale
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Cannot read image")
        
    # Resize & Normalize
    image = cv2.resize(image, (target_size, target_size))
    img_norm = image.astype(np.float32) / 255.0
    
    # Tensor: [1, 1, H, W] (Batch=1, Channel=1)
    img_tensor = torch.from_numpy(img_norm).unsqueeze(0).unsqueeze(0)
    return img_tensor, image

def compute_attention_difference(attn_logits):
    """
    TÃ­nh toÃ¡n sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p dá»±a trÃªn attention weights.
    Args:
        attn_logits: Tensor [Batch, Num_Classes, H, W] - Attention logits tá»« concept head.
    Returns:
        diff_matrix: Tensor [Num_Classes, Num_Classes] - Ma tráº­n sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p.
    """
    B, K, H, W = attn_logits.shape
    
    # 1. Normalize CAM (Spatial Softmax)
    attn_weights = F.softmax(attn_logits.view(B, K, -1), dim=-1).view(B, K, H, W)  # [B, K, H, W]
    
    # 2. TÃ­nh giÃ¡ trá»‹ trung bÃ¬nh cá»§a attention weights cho má»—i lá»›p
    class_means = attn_weights.mean(dim=(0, 2, 3))  # [K] - GiÃ¡ trá»‹ trung bÃ¬nh cho má»—i lá»›p
    
    # 3. TÃ­nh sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p
    diff_matrix = torch.abs(class_means.unsqueeze(0) - class_means.unsqueeze(1))  # [K, K]
    
    return diff_matrix

# --- HÃ€M HIá»‚N THá»Š Káº¾T QUáº¢ ---
def visualize_result(original_img, probs, similarities, attn_maps, top_k=3, save_path=None):
    """Váº½ áº£nh gá»‘c, káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  heatmap cá»§a top-k bá»‡nh, Ä‘á»“ng thá»i lÆ°u áº£nh náº¿u cáº§n"""
    top_indices = np.argsort(probs)[::-1][:top_k]
    
    plt.figure(figsize=(15, 6))
    
    # 1. áº¢nh gá»‘c + Text
    plt.subplot(1, top_k + 1, 1)
    plt.imshow(original_img, cmap='gray')
    plt.title("Input X-Ray")
    plt.axis('off')
    
    info_text = "PREDICTIONS:\n"
    for idx in top_indices:
        name = CLASS_NAMES[idx]
        sim_score = similarities[0, idx, :].max().item() 
        prob = probs[idx]
        info_text += f"{name}: {prob*100:.1f}% (Sim: {sim_score:.2f})\n"
        
    plt.xlabel(info_text, fontsize=12, loc='left')

    # 2. Heatmap cÃ¡c bá»‡nh Top K
    for i, idx in enumerate(top_indices):
        name = CLASS_NAMES[idx]
        
        # Láº¥y attention map (CAM)
        cam = attn_maps[0, idx].cpu().numpy()
        
        # Resize CAM lÃªn size áº£nh
        cam_resized = cv2.resize(cam, (original_img.shape[1], original_img.shape[0]))

        # Normalize CAM
        cam_norm = (cam_resized - cam_resized.min()) / (cam_resized.max() - cam_resized.min() + 1e-8)

        # ðŸ”¥ Táº¡o mask â€” chá»‰ highlight vÃ¹ng cam > threshold
        threshold = 0.8
        mask = (cam_norm > threshold).astype(np.float32)

        # Colormap chá»‰ Ã¡p dá»¥ng trÃªn vÃ¹ng mask
        heatmap = cv2.applyColorMap((cam_norm * 255).astype(np.uint8), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0

        # Chá»‰ giá»¯ mÃ u trong vÃ¹ng mask
        heatmap_masked = heatmap * mask[..., None]

        # Chuáº©n hÃ³a áº£nh gá»‘c (H,W â†’ RGB)
        img_rgb = cv2.cvtColor((original_img * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB).astype(np.float32) / 255.0

        # ðŸ”¥ Overlay CHá»ˆ á»Ÿ vÃ¹ng mask
        alpha = 0.5
        overlay = img_rgb * (1 - alpha * mask[..., None]) + heatmap_masked * (alpha * mask[..., None])

        plt.subplot(1, top_k + 1, i + 2)
        plt.imshow(overlay)
        plt.title(f"{name}\n{probs[idx]*100:.1f}%")
        plt.axis('off')

    plt.tight_layout()

    if save_path:
        save_dir = os.path.dirname(save_path)
        if save_dir and not os.path.exists(save_dir):
            os.makedirs(save_dir)
        plt.savefig(save_path, bbox_inches='tight')
        print(f"Result saved to: {save_path}")
    
    plt.show()

# --- CHáº Y INFERENCE ---
print("-> Loading CSRModel...")
model = CSRModel(num_classes=num_classes, num_prototypes=num_prototypes, model_name=model_name)

# Load checkpoint
ckpt = torch.load(checkpoint_path, map_location=device)
if 'model_state_dict' in ckpt:
    model.load_state_dict(ckpt['model_state_dict'])
else:
    model.load_state_dict(ckpt)

model.to(device)
model.eval()

# Tiá»n xá»­ lÃ½ áº£nh
img_tensor, original_img = preprocess_image(image_path)
img_tensor = img_tensor.to(device)

# Dá»± Ä‘oÃ¡n
print(f"-> Predicting: {image_path}")
with torch.no_grad():
    outputs = model(img_tensor)
    
    # Outputs tá»« CSRModel bao gá»“m: logits, sim_scores, attn_maps, ...
    logits = outputs['logits'][0]           # [Num_Classes]
    sim_scores = outputs['sim_scores']      # [Batch, Num_Classes, Num_Proto]
    attn_maps = outputs['attn_maps']        # [Batch, Num_Classes, H, W]

    # TÃ­nh sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c lá»›p
    # diff_matrix = compute_attention_difference(attn_maps)
    # print("Attention Difference Matrix:", diff_matrix)
        
    probs = torch.sigmoid(logits).cpu().numpy()

# Hiá»ƒn thá»‹ káº¿t quáº£
visualize_result(original_img, probs, sim_scores, attn_maps, save_path=save_path)