import torch
import torch.nn.functional as F
import torch.optim as optim
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.amp import GradScaler, autocast
from tqdm import tqdm
import argparse
import os
from pathlib import Path

# Import model v√† utils c·ªßa b·∫°n
from src.model import CSR 
from src.dataloader import get_dataloaders
from utils import PrototypeContrastiveLoss
from utils_bbox import BBoxGuidedConceptLoss
from focal_loss import FocalLoss, ClassBalancedLoss
import pandas as pd
import numpy as np

def setup_ddp():
    """Initialize DDP training environment."""
    dist.init_process_group(backend='nccl')
    local_rank = int(os.environ['LOCAL_RANK'])
    torch.cuda.set_device(local_rank)
    return local_rank

def cleanup_ddp():
    """Cleanup DDP training environment."""
    dist.destroy_process_group()

def parse_args():
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(description='CSR Model Training with DDP')
    
    # Data paths
    parser.add_argument('--train_csv', type=str, default='labels_train.csv', help='Path to training CSV')
    parser.add_argument('--test_csv', type=str, default='labels_test.csv', help='Path to test CSV')
    parser.add_argument('--train_bbox_csv', type=str, default=None, help='Path to train bbox annotations CSV (optional for Stage 1)')
    parser.add_argument('--test_bbox_csv', type=str, default=None, help='Path to test bbox annotations CSV (optional for Stage 1)')
    parser.add_argument('--train_resize_factor_csv', type=str, default=None, help='Path to train resize factor CSV (required when using bbox)')
    parser.add_argument('--test_resize_factor_csv', type=str, default=None, help='Path to test resize factor CSV (required when using bbox)')
    parser.add_argument('--train_dir', type=str, default='train/', help='Path to training images')
    parser.add_argument('--test_dir', type=str, default='test/', help='Path to test images')
    
    # Training hyperparameters
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size per GPU')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--epochs_stage1', type=int, default=10, help='Epochs for Stage 1')
    parser.add_argument('--epochs_stage2', type=int, default=10, help='Epochs for Stage 2')
    parser.add_argument('--epochs_stage3', type=int, default=10, help='Epochs for Stage 3')
    parser.add_argument('--alpha', type=float, default=1.0, help='Weight for classification loss (Stage 1 with bbox)')
    parser.add_argument('--beta', type=float, default=0.5, help='Weight for localization loss (Stage 1 with bbox)')
    
    # Model configuration
    parser.add_argument('--backbone_type', type=str, default='medmae', choices=['medmae', 'resnet50', 'vit'], help='Backbone type')
    parser.add_argument('--model_name', type=str, default='facebook/vit-mae-base', help='Pretrained model name or path')
    parser.add_argument('--num_prototypes', type=int, default=5, help='Number of prototypes per concept (M)')
    
    # Output
    parser.add_argument('--output_dir', type=str, default='checkpoints', help='Directory to save model checkpoints')
    parser.add_argument('--exp_name', type=str, default='csr_exp', help='Experiment name')
    
    return parser.parse_args()

def train_one_epoch(model, loader, optimizer, criterion, stage, scaler, device, rank):
    model.train()
    total_loss = 0
    
    # Progress bar (only show on rank 0)
    if rank == 0:
        loop = tqdm(loader, desc=f"Stage {stage}")
    else:
        loop = loader
    
    for batch in loop:
        images = batch['image'].to(device)
        concepts_gt = batch['concepts'].to(device) # Nh√£n concept (Ground Truth)
        targets_gt = batch['targets'].to(device)   # Nh√£n b·ªánh (Ground Truth)
        
        optimizer.zero_grad()
        
        # D√πng Mixed Precision ƒë·ªÉ train nhanh v√† nh·∫π h∆°n
        with autocast('cuda'):
            outputs = model(images)
            loss = 0
            
            # --- GIAI ƒêO·∫†N 1: Train Concept Model ---
            if stage == 1:
                # CAMs t·ª´ concept_head: (B, K, H, W)
                cams = outputs['cams']  # (B, K, H, W)
                
                # Check if using BBoxGuidedConceptLoss (needs spatial CAMs + bboxes)
                if hasattr(criterion, 'alpha') and hasattr(criterion, 'beta'):
                    # BBoxGuidedConceptLoss: Pass raw CAMs (does max pooling internally)
                    # Also need to pass bboxes if available
                    bboxes = batch.get('bboxes', None)
                    loss = criterion(cams, concepts_gt, bboxes)
                else:
                    # Standard BCEWithLogitsLoss: Need to max pool first
                    concept_logits = F.adaptive_max_pool2d(cams, (1, 1)).squeeze(-1).squeeze(-1)  # (B, K)
                    loss = criterion(concept_logits, concepts_gt)
            
            # --- GIAI ƒêO·∫†N 2: Train Prototypes (Contrastive) ---
            elif stage == 2:
                # DDP wrap: Ph·∫£i d√πng .module ƒë·ªÉ truy c·∫≠p methods c·ªßa model g·ªëc
                actual_model = model.module if hasattr(model, 'module') else model
                
                # Use projected features from forward pass: (B, 128, H, W)
                f_proj = outputs['projected_features']
                
                # Get local concept vectors in PROJECTED space
                # Apply CAM-weighted pooling to projected features
                local_vectors = actual_model.get_local_concept_vectors(f_proj, outputs['cams'])
                # (B, K, 128) - Already in projection space
                
                # T√≠nh Loss Contrastive
                # Ch·ªâ t√≠nh loss cho nh·ªØng concept c√≥ trong ·∫£nh (concepts_gt == 1)
                loss = criterion(local_vectors, actual_model.prototypes, concepts_gt, 
                                 num_prototypes_per_concept=actual_model.M)
                
            # --- GIAI ƒêO·∫†N 3: Train Task Head (Disease Prediction) ---
            elif stage == 3:
                # Logits cu·ªëi c√πng d·ª± ƒëo√°n b·ªánh
                preds = outputs['logits']
                # Target l√† multi-label th√¨ d√πng BCE, single-label d√πng CrossEntropy
                # ·ªû ƒë√¢y gi·∫£ s·ª≠ target c≈©ng l√† multi-label (v√¨ 1 ng∆∞·ªùi c√≥ th·ªÉ v·ª´a vi√™m ph·ªïi v·ª´a COPD)
                loss = criterion(preds, targets_gt)
        
        # Backward & Optimizer
        scaler.scale(loss).backward()
        
        # Gradient clipping ƒë·ªÉ tr√°nh exploding gradients
        scaler.unscale_(optimizer)
        
        # Monitor gradients (every 10 batches)
        if rank == 0 and len(loop.iterable) > 0:
            batch_idx = loop.n
            if batch_idx % 10 == 0:
                total_norm = 0
                for p in model.parameters():
                    if p.grad is not None:
                        total_norm += p.grad.data.norm(2).item() ** 2
                total_norm = total_norm ** 0.5
                if total_norm < 1e-7:
                    print(f"\n‚ö†Ô∏è Vanishing gradients detected! Norm: {total_norm:.2e}")
                elif total_norm > 100:
                    print(f"\n‚ö†Ô∏è Exploding gradients detected! Norm: {total_norm:.2e}")
        
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        scaler.step(optimizer)
        scaler.update()
        
        total_loss += loss.item()
        if rank == 0:
            loop.set_postfix(loss=loss.item())
        
    return total_loss / len(loader)

def compute_metrics(preds, targets, threshold=0.5):
    """Compute comprehensive metrics for multi-label classification."""
    from sklearn.metrics import roc_auc_score, average_precision_score, f1_score
    
    metrics = {}
    
    # Valid classes (have both positive and negative samples)
    valid_classes = (targets.sum(axis=0) > 0) & (targets.sum(axis=0) < len(targets))
    
    if valid_classes.sum() > 0:
        # AUC-ROC
        try:
            auc = roc_auc_score(targets[:, valid_classes], preds[:, valid_classes], average='macro')
            metrics['auc'] = auc
        except:
            metrics['auc'] = 0.0
        
        # mAP (mean Average Precision)
        try:
            map_score = average_precision_score(targets[:, valid_classes], preds[:, valid_classes], average='macro')
            metrics['mAP'] = map_score
        except:
            metrics['mAP'] = 0.0
        
        # F1 Score (with threshold)
        try:
            preds_binary = (preds[:, valid_classes] > threshold).astype(int)
            f1_macro = f1_score(targets[:, valid_classes], preds_binary, average='macro', zero_division=0)
            f1_micro = f1_score(targets[:, valid_classes], preds_binary, average='micro', zero_division=0)
            metrics['f1_macro'] = f1_macro
            metrics['f1_micro'] = f1_micro
        except:
            metrics['f1_macro'] = 0.0
            metrics['f1_micro'] = 0.0
    else:
        metrics = {'auc': 0.0, 'mAP': 0.0, 'f1_macro': 0.0, 'f1_micro': 0.0}
    
    return metrics

def compute_iou_score(cams, bboxes, threshold=0.5):
    """Compute IoU between CAM heatmaps and ground truth bounding boxes.
    
    Args:
        cams: (B, K, H, W) concept activation maps
        bboxes: List of bbox lists for each sample
        threshold: Threshold to binarize CAMs
    
    Returns:
        mean_iou: Average IoU across all concepts with bboxes
    """
    if not bboxes or len(bboxes) == 0:
        return 0.0
    
    ious = []
    B, K, H, W = cams.shape
    
    # Apply sigmoid and threshold to get binary masks
    cam_masks = (torch.sigmoid(cams) > threshold).float()
    
    for batch_idx, sample_bboxes in enumerate(bboxes):
        if sample_bboxes is None or len(sample_bboxes) == 0:
            continue
        
        for bbox_info in sample_bboxes:
            concept_idx = bbox_info['concept_idx']
            bbox = bbox_info['bbox']  # [x_min, y_min, x_max, y_max] normalized [0, 1]
            
            # Get CAM mask for this concept
            cam_mask = cam_masks[batch_idx, concept_idx]  # (H, W)
            
            # Create bbox mask
            x_min, y_min, x_max, y_max = bbox
            x_min_px = int(x_min * W)
            x_max_px = int(x_max * W)
            y_min_px = int(y_min * H)
            y_max_px = int(y_max * H)
            
            bbox_mask = torch.zeros_like(cam_mask)
            bbox_mask[y_min_px:y_max_px, x_min_px:x_max_px] = 1.0
            
            # Compute IoU
            intersection = (cam_mask * bbox_mask).sum()
            union = ((cam_mask + bbox_mask) > 0).float().sum()
            
            if union > 0:
                iou = (intersection / union).item()
                ious.append(iou)
    
    return np.mean(ious) if len(ious) > 0 else 0.0

def validate(model, loader, device, rank=0, stage=3, criterion=None, compute_iou=False):
    """Validation function with comprehensive metrics.
    
    Args:
        stage: 1 = Concept Learning, 3 = Task Learning
        criterion: Loss function
        compute_iou: Whether to compute IoU with bboxes (Stage 1 only)
    """
    model.eval()
    total_loss = 0
    all_preds = []
    all_targets = []
    all_cams = []
    all_bboxes = []
    
    if criterion is None:
        criterion = torch.nn.BCEWithLogitsLoss()
    
    with torch.no_grad():
        if rank == 0:
            pbar = tqdm(loader, desc="Validating")
        else:
            pbar = loader
        
        for batch in pbar:
            images = batch['image'].to(device)
            concepts = batch['concepts'].to(device)
            targets = batch['targets'].to(device)
            
            outputs = model(images)
            
            # Stage 1: Validate concept prediction
            if stage == 1:
                cams = outputs['cams']
                concept_logits = F.adaptive_max_pool2d(cams, (1, 1)).squeeze(-1).squeeze(-1)
                
                # Check if using BBoxGuidedConceptLoss
                if hasattr(criterion, 'alpha') and hasattr(criterion, 'beta'):
                    # BBoxGuidedConceptLoss: Pass raw CAMs
                    bboxes = batch.get('bboxes', None)
                    loss = criterion(cams, concepts, bboxes)
                else:
                    # Standard BCE: Use max-pooled logits
                    loss = criterion(concept_logits, concepts)
                    bboxes = batch.get('bboxes', [])
                
                all_preds.append(torch.sigmoid(concept_logits).cpu())
                all_targets.append(concepts.cpu())
                
                if compute_iou and 'bboxes' in batch:
                    all_cams.append(cams.cpu())
                    all_bboxes.extend(batch['bboxes'])
            
            # Stage 3: Validate disease prediction
            else:
                loss = criterion(outputs['logits'], targets)
                all_preds.append(torch.sigmoid(outputs['logits']).cpu())
                all_targets.append(targets.cpu())
            
            total_loss += loss.item()
    
    # Compute metrics
    preds = torch.cat(all_preds).numpy()
    targets = torch.cat(all_targets).numpy()
    
    metrics = compute_metrics(preds, targets)
    metrics['loss'] = total_loss / len(loader)
    
    # Compute IoU if requested
    if compute_iou and len(all_cams) > 0 and stage == 1:
        all_cams_tensor = torch.cat(all_cams)
        iou = compute_iou_score(all_cams_tensor, all_bboxes)
        metrics['iou'] = iou
    
    return metrics

def main():
    # Parse arguments
    args = parse_args()
    
    # Setup DDP
    local_rank = setup_ddp()
    device = torch.device(f'cuda:{local_rank}')
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    
    # Create output directory
    if rank == 0:
        output_dir = Path(args.output_dir) / args.exp_name
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"Output directory: {output_dir}")
    
    # 1. Prepare Data
    # Use bbox dataloader if bbox_csv is provided
    if args.train_bbox_csv and args.test_bbox_csv:
        from src.dataloader_bbox_simple import get_dataloaders_with_bbox_simple
        
        if rank == 0:
            print(f"Loading data WITH bounding boxes (Simple - bbox already in 224x224 space):")
            print(f"  - Train bbox: {args.train_bbox_csv}")
            print(f"  - Test bbox: {args.test_bbox_csv}")
            print(f"  ‚ö†Ô∏è  Assuming bbox coordinates are ALREADY adjusted for 224x224 images")
        
        train_loader, val_loader, test_loader, num_concepts, num_classes, train_sampler = get_dataloaders_with_bbox_simple(
            args.train_csv, args.test_csv, args.train_bbox_csv, args.test_bbox_csv,
            args.train_dir, args.test_dir,
            batch_size=args.batch_size,
            rank=rank,
            world_size=world_size,
            val_split=0.1  # 10% c·ªßa training set l√†m validation
        )
    elif args.train_bbox_csv or args.test_bbox_csv:
        raise ValueError("Both --train_bbox_csv and --test_bbox_csv must be provided together")
    else:
        if rank == 0:
            print("Loading data WITHOUT bounding boxes (standard dataloader)")
        train_loader, val_loader, test_loader, num_concepts, num_classes, train_sampler = get_dataloaders(
            args.train_csv, args.test_csv, args.train_dir, args.test_dir, 
            batch_size=args.batch_size,
            rank=rank,
            world_size=world_size,
            val_split=0.1  # 10% c·ªßa training set l√†m validation
        )
    
    if rank == 0:
        print(f"Data Loaded: {num_concepts} Concepts, {num_classes} Diseases")
        print(f"Train size: {len(train_loader.dataset)}, Val size: {len(val_loader.dataset)}, Test size: {len(test_loader.dataset)}")
        print(f"World Size: {world_size}, Batch Size per GPU: {args.batch_size}")
        if world_size > 1:
            print(f"‚úÖ DDP enabled: Each GPU trains on {len(train_loader.dataset) // world_size} samples")

    # 2. Model Init (D√πng MedMAE backbone)
    model = CSR(
        num_concepts=num_concepts, 
        num_classes=num_classes,
        num_prototypes_per_concept=args.num_prototypes,
        backbone_type=args.backbone_type,
        model_name=args.model_name
    ).to(device)
    
    # Wrap with DDP
    # find_unused_parameters=True v√¨ c√°c stage kh√°c nhau d√πng c√°c parameters kh√°c nhau
    model = DDP(model, device_ids=[local_rank], output_device=local_rank, find_unused_parameters=True)
    
    # PyTorch 2.6: torch.amp.GradScaler thay v√¨ torch.cuda.amp.GradScaler
    from torch.amp import GradScaler
    scaler = GradScaler('cuda') # Cho AMP
    
    # Best model tracking
    best_auc = 0.0
    best_stage = None

    # ====================================================
    # GIAI ƒêO·∫†N 1: Concept Learning
    # M·ª•c ti√™u: H·ªçc CAMs chu·∫©n. Train Backbone + Concept Head
    # ====================================================
    if rank == 0:
        print("\n--- START STAGE 1: Concept Learning ---")
    
    # T√≠nh pos_weight ƒë·ªÉ x·ª≠ l√Ω class imbalance
    # T√≠nh tr·ª±c ti·∫øp t·ª´ CSV thay v√¨ load ·∫£nh (nhanh h∆°n 100x)
    if rank == 0:
        print("Computing pos_weight for balanced BCE loss...")
        import pandas as pd
        df_train = pd.read_csv(args.train_csv)
        
        # IMPORTANT: Filter rare classes SAME as dataloader
        from src.dataloader_bbox_simple import CSRDatasetWithBBoxSimple
        RARE_CLASSES = CSRDatasetWithBBoxSimple.RARE_CLASSES
        
        # L·∫•y concept columns (gi·ªëng logic trong dataloader)
        meta_cols = ['image_id', 'rad_id']
        target_keywords = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'No finding']
        target_cols = []
        for col in df_train.columns:
            if col in meta_cols:
                continue
            if 'other' in col.lower():
                if 'disease' in col.lower():
                    target_cols.append(col)
                continue
            if any(keyword.lower() in col.lower() for keyword in target_keywords):
                target_cols.append(col)
        concept_cols = [c for c in df_train.columns if c not in target_cols + meta_cols]
        
        # FILTER RARE CLASSES (same as dataloader)
        concept_cols = [c for c in concept_cols if c not in RARE_CLASSES]
        target_cols = [c for c in target_cols if c not in RARE_CLASSES]
        
        # Aggregate nh∆∞ trong dataset
        df_agg = df_train.groupby('image_id')[concept_cols + target_cols].max().reset_index()
        
        # T√≠nh pos_weight t·ª´ concept columns (now filtered)
        concept_values = torch.tensor(df_agg[concept_cols].values, dtype=torch.float32)
        pos_weight = (concept_values == 0).sum(dim=0) / (concept_values == 1).sum(dim=0).clamp(min=1)
        # Clip pos_weight ƒë·ªÉ tr√°nh loss qu√° extreme (max 20x)
        pos_weight = pos_weight.clamp(max=20.0)
        print(f"Pos weights for {len(concept_cols)} concepts (after filtering rare classes)")
        print(f"Pos weights range: {pos_weight.min():.2f} - {pos_weight.max():.2f} (clipped to max 20)")
    else:
        # C√°c rank kh√°c d√πng uniform weights (s·∫Ω ƒë∆∞·ª£c broadcast t·ª´ rank 0)
        pos_weight = torch.ones(num_concepts)
    
    # Stage 1: FIXED learning rates - previous were too low!
    # Backbone needs fine-tuning even with pretrained weights
    optimizer = optim.AdamW([
        {'params': model.module.backbone.parameters(), 'lr': args.lr * 0.1},  # 1e-5 (was 1e-6)
        {'params': model.module.concept_head.parameters(), 'lr': args.lr}      # 1e-4 (was 2e-5)
    ])
    
    # Use BBoxGuidedConceptLoss if bboxes available, else standard BCE
    if args.train_bbox_csv and args.test_bbox_csv:
        if rank == 0:
            print(f"Using BBoxGuidedConceptLoss (alpha={args.alpha}, beta={args.beta}) with pos_weight")
        criterion_s1 = BBoxGuidedConceptLoss(
            alpha=args.alpha, 
            beta=args.beta, 
            pos_weight=pos_weight.to(device)
        )
    else:
        if rank == 0:
            print(f"Using BCEWithLogitsLoss with pos_weight")
        criterion_s1 = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))
    
    for epoch in range(args.epochs_stage1):
        # Set epoch for DistributedSampler to shuffle differently each epoch
        if train_sampler is not None:
            train_sampler.set_epoch(epoch)
        
        loss = train_one_epoch(model, train_loader, optimizer, criterion_s1, stage=1, scaler=scaler, device=device, rank=rank)
        if rank == 0:
            print(f"Epoch {epoch+1}: Train Loss {loss:.4f}")
        
        # Validate (only on rank 0)
        if rank == 0:
            metrics = validate(model.module, val_loader, device, rank, stage=1, criterion=criterion_s1)
            # Show comprehensive metrics for Stage 1
            print(f"Epoch {epoch+1}: Val Loss {metrics['loss']:.4f}, AUC {metrics['auc']:.4f}, "
                  f"mAP {metrics['mAP']:.4f}, F1-macro {metrics['f1_macro']:.4f}, F1-micro {metrics['f1_micro']:.4f}", end="")
            if 'iou' in metrics:
                print(f", IoU {metrics['iou']:.4f}")
            else:
                print()  # newline
            
            # Save best model (based on AUC)
            if metrics['auc'] > best_auc:
                best_auc = metrics['auc']
                best_stage = 'stage1'
                torch.save(model.module.state_dict(), output_dir / 'best_model_stage1.pth')
                print(f"‚úÖ Saved best Stage 1 model (Concept AUC: {best_auc:.4f}, mAP: {metrics['mAP']:.4f})")

    # ====================================================
    # GIAI ƒêO·∫†N 2: Prototype Learning
    # M·ª•c ti√™u: H·ªçc Prototypes chu·∫©n. Freeze Backbone.
    # ====================================================
    if rank == 0:
        print("\n--- START STAGE 2: Prototype Learning ---")
        print(f"  Stage 2 Learning Rate: {args.lr * 10:.6f} (10x Stage 1)")
    # Freeze Backbone & Concept Head
    for param in model.module.backbone.parameters(): param.requires_grad = False
    for param in model.module.concept_head.parameters(): param.requires_grad = False
    
    # Ch·ªâ train Projector v√† Prototypes with 10x learning rate
    optimizer = optim.AdamW([
        {'params': model.module.projector.parameters(), 'lr': args.lr * 10},
        {'params': model.module.prototypes, 'lr': args.lr * 10}
    ])
    # FIXED: Increased temperature from 0.1 to 0.3 for more stable training
    criterion_s2 = PrototypeContrastiveLoss(temperature=0.3) # Custom Loss
    
    for epoch in range(args.epochs_stage2):
        # Set epoch for proper shuffling
        if train_sampler is not None:
            train_sampler.set_epoch(epoch)
        
        loss = train_one_epoch(model, train_loader, optimizer, criterion_s2, stage=2, scaler=scaler, device=device, rank=rank)
        if rank == 0:
            print(f"Epoch {epoch+1}: Loss {loss:.4f}")
            
            # ADDED: Monitor prototype quality every 5 epochs
            if epoch % 5 == 0 or epoch == args.epochs_stage2 - 1:
                with torch.no_grad():
                    # Check prototype diversity (should be high for good separation)
                    protos = model.module.prototypes.squeeze(-1).squeeze(-1)  # (K*M, 128)
                    protos_norm = F.normalize(protos, p=2, dim=1)
                    
                    # Compute pairwise cosine similarity
                    similarity_matrix = torch.mm(protos_norm, protos_norm.t())
                    
                    # Remove diagonal (self-similarity)
                    mask = ~torch.eye(len(protos), dtype=torch.bool, device=device)
                    avg_similarity = similarity_matrix[mask].mean().item()
                    max_similarity = similarity_matrix[mask].max().item()
                    
                    print(f"  Prototype Diversity: avg_sim={avg_similarity:.4f}, max_sim={max_similarity:.4f}")
                    print(f"  (Want avg < 0.5 for good separation)")
                    
                    if avg_similarity > 0.8:
                        print(f"  ‚ö†Ô∏è WARNING: Prototypes collapsing! Consider increasing temperature or LR.")
                
                # Save checkpoint
                torch.save(model.module.state_dict(), output_dir / f'model_stage2_epoch{epoch+1}.pth')
        
    # ====================================================
    # GIAI ƒêO·∫†N 3: Task Learning
    # M·ª•c ti√™u: D·ª± ƒëo√°n b·ªánh. Freeze t·∫•t c·∫£ tr·ª´ Task Head.
    # ====================================================
    if rank == 0:
        print("\n--- START STAGE 3: Task Learning ---")
    
    # Freeze ALL previous layers (Backbone, Concept Head, Projector, Prototypes)
    # Only Task Head should be trainable
    for param in model.module.backbone.parameters(): param.requires_grad = False
    for param in model.module.concept_head.parameters(): param.requires_grad = False
    for param in model.module.projector.parameters(): param.requires_grad = False
    model.module.prototypes.requires_grad = False
    
    # Compute class distribution for balanced loss (only on rank 0)
    if rank == 0:
        print("Computing class distribution for Focal Loss...")
        # Get target distribution from aggregated data (already filtered in Stage 1)
        print(f"Using {len(target_cols)} target classes: {target_cols}")
        target_values = torch.tensor(df_agg[target_cols].values, dtype=torch.float32)
        samples_per_class = target_values.sum(dim=0)
        print(f"Samples per disease class: {samples_per_class.tolist()}")
        
        # Sanity check: ensure dimensions match
        assert len(samples_per_class) == num_classes, \
            f"Mismatch: samples_per_class has {len(samples_per_class)} but num_classes={num_classes}"
        
        # Compute class weights (inverse frequency, clamped)
        class_weights = len(df_agg) / (samples_per_class * num_classes).clamp(min=1)
        class_weights = class_weights.clamp(max=10.0)  # Limit max weight to 10x
        print(f"Class weights: {class_weights.tolist()}")
    else:
        samples_per_class = torch.ones(num_classes)
        class_weights = torch.ones(num_classes)
    
    # Ch·ªâ train Task Head
    optimizer = optim.AdamW(model.module.task_head.parameters(), lr=args.lr)
    
    # Use Focal Loss for severe class imbalance (better than BCE for medical data)
    # alpha=0.25, gamma=2.0 are standard values that work well
    criterion_s3 = FocalLoss(alpha=0.25, gamma=2.0)
    
    if rank == 0:
        print(f"Using Focal Loss (alpha=0.25, gamma=2.0) for class imbalance handling")
    
    for epoch in range(args.epochs_stage3):
        # Set epoch for proper shuffling
        if train_sampler is not None:
            train_sampler.set_epoch(epoch)
        
        loss = train_one_epoch(model, train_loader, optimizer, criterion_s3, stage=3, scaler=scaler, device=device, rank=rank)
        if rank == 0:
            print(f"Epoch {epoch+1}: Train Loss {loss:.4f}")
        
        # Validate (only on rank 0)
        if rank == 0:
            metrics = validate(model.module, val_loader, device, rank, stage=3, criterion=criterion_s3)
            # Show comprehensive metrics for Stage 3
            print(f"Epoch {epoch+1}: Val Loss {metrics['loss']:.4f}, Disease AUC {metrics['auc']:.4f}, "
                  f"mAP {metrics['mAP']:.4f}, F1-macro {metrics['f1_macro']:.4f}, F1-micro {metrics['f1_micro']:.4f}")
            
            # Save best model (based on AUC)
            if metrics['auc'] > best_auc:
                best_auc = metrics['auc']
                best_stage = 'stage3'
                torch.save(model.module.state_dict(), output_dir / 'best_model_stage3.pth')
                print(f"‚úÖ Saved best Stage 3 model (Disease AUC: {best_auc:.4f}, mAP: {metrics['mAP']:.4f})")
    
    # ====================================================
    # FINAL TEST: ƒê√°nh gi√° tr√™n test set sau khi train xong h·∫øt
    # ====================================================
    if rank == 0:
        print("\n" + "="*60)
        print("FINAL EVALUATION ON TEST SET")
        print("="*60)
        
        # Load best model
        best_model_path = output_dir / 'best_model_stage3.pth'
        if best_model_path.exists():
            print(f"Loading best model from {best_model_path}")
            model.module.load_state_dict(torch.load(best_model_path))
        
        # Test (d√πng BCE loss kh√¥ng pos_weight cho fair comparison)
        test_criterion = torch.nn.BCEWithLogitsLoss()
        test_metrics = validate(model.module, test_loader, device, rank, stage=3, criterion=test_criterion)
        print(f"\nüèÜ Final Test Results (Disease Prediction):")
        print(f"  Test Loss: {test_metrics['loss']:.4f}")
        print(f"  Test AUC (macro): {test_metrics['auc']:.4f}")
        print(f"  Test mAP: {test_metrics['mAP']:.4f}")
        print(f"  Test F1-macro: {test_metrics['f1_macro']:.4f}")
        print(f"  Test F1-micro: {test_metrics['f1_micro']:.4f}")
        print(f"  {'Excellent!' if test_metrics['auc'] >= 0.85 else 'Very Good!' if test_metrics['auc'] >= 0.80 else 'Good!' if test_metrics['auc'] >= 0.75 else 'Fair' if test_metrics['auc'] >= 0.70 else 'Needs Improvement'}")
        print(f"\nüéâ Training Complete!")
        print(f"Best Val AUC: {best_auc:.4f} from {best_stage}")
        print(f"Final Test Disease AUC: {test_metrics['auc']:.4f}, mAP: {test_metrics['mAP']:.4f}")
        print(f"\nBenchmark: VinDr-CXR ResNet-50 ~0.78 | DenseNet-121 ~0.82 | SOTA ~0.87")
        print(f"All checkpoints saved to: {output_dir}")
    
    # Save Final Model
    if rank == 0:
        torch.save(model.module.state_dict(), output_dir / "final_model.pth")
    
    # Cleanup DDP
    cleanup_ddp()

if __name__ == "__main__":
    main()