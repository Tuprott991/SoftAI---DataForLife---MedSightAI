"""
Script Ä‘á»ƒ preprocess DICOM thÃ nh PNG/JPG nhanh nháº¥t cÃ³ thá»ƒ.
Sá»­ dá»¥ng multiprocessing Ä‘á»ƒ xá»­ lÃ½ song song trÃªn nhiá»u CPU cores.

Usage:
    python preprocess_dicom.py --input_dir train/ --output_dir train_png/ --num_workers 8
"""

import os
import argparse
from pathlib import Path
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import pandas as pd
from utils import dicom_to_image
from PIL import Image

def process_single_dicom(args):
    """
    Xá»­ lÃ½ 1 file DICOM thÃ nh PNG.
    Args: tuple (dicom_path, output_path)
    """
    dicom_path, output_path = args
    
    try:
        # Kiá»ƒm tra náº¿u output Ä‘Ã£ tá»“n táº¡i â†’ skip
        if os.path.exists(output_path):
            return True, None
        
        # Äá»c vÃ  xá»­ lÃ½ DICOM
        img = dicom_to_image(dicom_path, size=(224, 224))
        
        # LÆ°u thÃ nh PNG (hoáº·c JPG náº¿u muá»‘n tiáº¿t kiá»‡m dung lÆ°á»£ng)
        img.save(output_path, 'PNG', optimize=True)
        
        return True, None
    except Exception as e:
        return False, f"{dicom_path}: {str(e)}"

def preprocess_dataset(input_dir, output_dir, csv_file=None, num_workers=None, format='png'):
    """
    Preprocess toÃ n bá»™ dataset DICOM thÃ nh PNG/JPG.
    
    Args:
        input_dir: Folder chá»©a DICOM files
        output_dir: Folder output cho PNG/JPG
        csv_file: File CSV chá»©a danh sÃ¡ch image_id (optional, náº¿u None sáº½ process táº¥t cáº£)
        num_workers: Sá»‘ CPU cores dÃ¹ng (None = auto detect)
        format: 'png' hoáº·c 'jpg'
    """
    # Create output directory
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # Auto detect sá»‘ workers
    if num_workers is None:
        num_workers = max(1, cpu_count() - 2)  # Äá»ƒ láº¡i 2 cores cho system
    
    print(f"ðŸš€ Starting preprocessing with {num_workers} workers...")
    print(f"ðŸ“‚ Input: {input_dir}")
    print(f"ðŸ“‚ Output: {output_dir}")
    print(f"ðŸŽ¨ Format: {format.upper()}")
    
    # Láº¥y danh sÃ¡ch files cáº§n xá»­ lÃ½
    if csv_file and os.path.exists(csv_file):
        # Náº¿u cÃ³ CSV, chá»‰ process cÃ¡c áº£nh trong CSV
        df = pd.read_csv(csv_file)
        image_ids = df['image_id'].unique()
        print(f"ðŸ“‹ Found {len(image_ids)} unique images in CSV")
    else:
        # Náº¿u khÃ´ng cÃ³ CSV, process táº¥t cáº£ files trong folder
        image_ids = [f.stem for f in Path(input_dir).glob('*.dicom')]
        if len(image_ids) == 0:
            # Try without extension
            image_ids = [f.stem for f in Path(input_dir).iterdir() if f.is_file()]
        print(f"ðŸ“‹ Found {len(image_ids)} DICOM files in directory")
    
    # Chuáº©n bá»‹ tasks cho multiprocessing
    tasks = []
    for img_id in image_ids:
        # TÃ¬m file DICOM (cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng cÃ³ extension)
        dicom_path = Path(input_dir) / f"{img_id}.dicom"
        if not dicom_path.exists():
            dicom_path = Path(input_dir) / img_id
        
        if not dicom_path.exists():
            print(f"âš ï¸  Skip {img_id}: file not found")
            continue
        
        output_path = Path(output_dir) / f"{img_id}.{format}"
        tasks.append((str(dicom_path), str(output_path)))
    
    print(f"ðŸ“¦ Total tasks: {len(tasks)}")
    
    # Process vá»›i multiprocessing + progress bar
    success_count = 0
    error_count = 0
    errors = []
    
    with Pool(processes=num_workers) as pool:
        results = list(tqdm(
            pool.imap(process_single_dicom, tasks),
            total=len(tasks),
            desc="Processing",
            unit="images"
        ))
    
    # Äáº¿m káº¿t quáº£
    for success, error_msg in results:
        if success:
            success_count += 1
        else:
            error_count += 1
            if error_msg:
                errors.append(error_msg)
    
    # In káº¿t quáº£
    print(f"\nâœ… Successfully processed: {success_count}/{len(tasks)}")
    if error_count > 0:
        print(f"âŒ Errors: {error_count}")
        print("\nFirst 10 errors:")
        for error in errors[:10]:
            print(f"  - {error}")
    
    print(f"\nðŸŽ‰ Done! Output saved to: {output_dir}")
    
    # TÃ­nh dung lÆ°á»£ng tiáº¿t kiá»‡m
    if success_count > 0:
        sample_dicom = Path(tasks[0][0])
        sample_png = Path(tasks[0][1])
        if sample_dicom.exists() and sample_png.exists():
            dicom_size = sample_dicom.stat().st_size / 1024 / 1024  # MB
            png_size = sample_png.stat().st_size / 1024 / 1024
            ratio = (dicom_size / png_size) if png_size > 0 else 0
            print(f"ðŸ“Š Size comparison (1 sample):")
            print(f"   DICOM: {dicom_size:.2f} MB")
            print(f"   {format.upper()}: {png_size:.2f} MB")
            print(f"   Ratio: {ratio:.1f}x")

def main():
    parser = argparse.ArgumentParser(description='Preprocess DICOM to PNG/JPG for faster training')
    
    parser.add_argument('--input_dir', type=str, required=True, 
                        help='Input directory containing DICOM files')
    parser.add_argument('--output_dir', type=str, required=True,
                        help='Output directory for PNG/JPG files')
    parser.add_argument('--csv_file', type=str, default=None,
                        help='CSV file with image_id column (optional)')
    parser.add_argument('--num_workers', type=int, default=None,
                        help='Number of CPU workers (default: auto)')
    parser.add_argument('--format', type=str, default='png', choices=['png', 'jpg'],
                        help='Output format: png or jpg (default: png)')
    
    args = parser.parse_args()
    
    preprocess_dataset(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        csv_file=args.csv_file,
        num_workers=args.num_workers,
        format=args.format
    )

if __name__ == '__main__':
    main()
